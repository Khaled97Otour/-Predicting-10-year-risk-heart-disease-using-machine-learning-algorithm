{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "%matplotlib inline  \n",
    "df = pd.read_csv('framingham.csv')\n",
    "\n",
    "fig, ax = plt.subplots(3,5,figsize=(15, 15))\n",
    "df1 = df.drop('TenYearCHD',axis=1)\n",
    "a = df1.columns\n",
    "a = np.asarray(a)\n",
    "a = a.reshape(3,5)\n",
    "for i in range (3):\n",
    "    for j in range(5):\n",
    "        ax[i,j].hist(df[a[i,j]])\n",
    "        ax[i,j].set_title(a[i,j])\n",
    "\n",
    "Due to most of the data are encoded to fill the NAN value I used the forwerd fill method.\n",
    "The countiues features were also filled after reading the data describtion and observe the histogram of each feature, as turns out there are no outliners.\n",
    "df.drop(['education','BPMeds','prevalentStroke','diabetes'],axis=1,inplace=True)\n",
    "df = df.fillna(method='ffill')\n",
    "y = df.TenYearCHD\n",
    "x = df.drop('TenYearCHD',axis=1)\n",
    "print(y.shape)\n",
    "print(x.shape)\n",
    "(4238,)\n",
    "(4238, 11)\n",
    "building the model:\n",
    "For classification first I will build a normail logictic model and study the results.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "lr = LogisticRegression(solver='liblinear').fit(X_train, y_train)\n",
    "lr_l1 = LogisticRegressionCV(Cs=10, cv=4, penalty='l1', solver='liblinear').fit(X_train, y_train)\n",
    "lr_l2 = LogisticRegressionCV(Cs=10, cv=4, penalty='l2', solver='liblinear').fit(X_train, y_train)\n",
    "coefficients = list()\n",
    "\n",
    "coeff_labels = ['lr', 'l1', 'l2']\n",
    "coeff_models = [lr, lr_l1, lr_l2]\n",
    "\n",
    "for lab,mod in zip(coeff_labels, coeff_models):\n",
    "    coeffs = mod.coef_\n",
    "    coeff_label = pd.MultiIndex(levels=[[lab], [0]], \n",
    "                                 codes=[[0], [0]])\n",
    "    coefficients.append(pd.DataFrame(coeffs.T, columns=coeff_label))\n",
    "\n",
    "coefficients = pd.concat(coefficients, axis=1)\n",
    "\n",
    "y_pred = list()\n",
    "y_prob = list()\n",
    "\n",
    "coeff_labels = ['lr', 'l1', 'l2']\n",
    "coeff_models = [lr, lr_l1, lr_l2]\n",
    "\n",
    "for lab,mod in zip(coeff_labels, coeff_models):\n",
    "    y_pred.append(pd.Series(mod.predict(X_test), name=lab))\n",
    "    y_prob.append(pd.Series(mod.predict_proba(X_test).max(axis=1), name=lab))\n",
    "    \n",
    "y_pred = pd.concat(y_pred, axis=1)\n",
    "y_prob = pd.concat(y_prob, axis=1)\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "metrics = list()\n",
    "cm = dict()\n",
    "\n",
    "for lab in coeff_labels:\n",
    "\n",
    "    # Preciision, recall, f-score from the multi-class support function\n",
    "    precision, recall, fscore, _ = score(y_test, y_pred[lab], average='weighted')\n",
    "    \n",
    "    # The usual way to calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred[lab])\n",
    "    \n",
    "    # ROC-AUC scores can be calculated by binarizing the data\n",
    "    auc = roc_auc_score(label_binarize(y_test, classes=[0,1]),\n",
    "              label_binarize(y_pred[lab], classes=[0,1]), \n",
    "              average='weighted')\n",
    "    \n",
    "    # Last, the confusion matrix\n",
    "    cm[lab] = confusion_matrix(y_test, y_pred[lab])\n",
    "    \n",
    "    metrics.append(pd.Series({'precision':precision, 'recall':recall, \n",
    "                              'fscore':fscore, 'accuracy':accuracy,\n",
    "                              'auc':auc}, \n",
    "                             name=lab))\n",
    "\n",
    "metrics = pd.concat(metrics, axis=1)\n",
    "print(metrics)\n",
    "\n",
    "fig, axList = plt.subplots(nrows=2, ncols=2)\n",
    "axList = axList.flatten()\n",
    "fig.set_size_inches(12, 10)\n",
    "\n",
    "axList[-1].axis('off')\n",
    "\n",
    "for ax,lab in zip(axList[:-1], coeff_labels):\n",
    "    sns.heatmap(cm[lab], ax=ax, annot=True, fmt='d');\n",
    "    ax.set(title=lab);\n",
    "    \n",
    "plt.tight_layout()\n",
    "\n",
    "As reading the results we found that LogisticRegression_l1 has the better predection eaven though the numbers were close, we have to try deffernt methods and models to pick the best one\n",
    "\n",
    "KNN model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, f1_score\n",
    "max_k = 50\n",
    "f1_scores = list()\n",
    "error_rates = list() # 1-accuracy\n",
    "\n",
    "for k in range(1, max_k):\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=k, weights='distance')\n",
    "    knn = knn.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = knn.predict(X_test)\n",
    "    f1 = f1_score(y_pred, y_test)\n",
    "    f1_scores.append((k, round(f1_score(y_test, y_pred), 4)))\n",
    "    error = 1-round(accuracy_score(y_test, y_pred), 4)\n",
    "    error_rates.append((k, error))\n",
    "    \n",
    "f1_results = pd.DataFrame(f1_scores, columns=['K', 'F1 Score'])\n",
    "error_results = pd.DataFrame(error_rates, columns=['K', 'Error Rate'])\n",
    "sns.set_context('talk')\n",
    "sns.set_style('ticks')\n",
    "\n",
    "plt.figure(dpi=300)\n",
    "ax = f1_results.set_index('K').plot(figsize=(12, 12), linewidth=6)\n",
    "ax.set(xlabel='K', ylabel='F1 Score')\n",
    "ax.set_xticks(range(1, max_k, 2));\n",
    "plt.title('KNN F1 Score')\n",
    "plt.savefig('knn_f1.png')\n",
    "\n",
    "sns.set_context('talk')\n",
    "sns.set_style('ticks')\n",
    "\n",
    "plt.figure(dpi=300)\n",
    "ax = error_results.set_index('K').plot(figsize=(12, 12), linewidth=6)\n",
    "ax.set(xlabel='K', ylabel='Error Rate')\n",
    "ax.set_xticks(range(1, max_k, 2))\n",
    "plt.title('KNN Elbow Curve')\n",
    "plt.savefig('knn_elbow.png')\n",
    "<Figure size 1800x1200 with 0 Axes>\n",
    "\n",
    "by reading the previous results the Kmean model is not suitable because the F1 score is to low\n",
    "\n",
    "Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt = dt.fit(X_train, y_train)\n",
    "dt.tree_.node_count, dt.tree_.max_depth\n",
    "(873, 24)\n",
    "A function to return error metrics.\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def measure_error(y_true, y_pred, label):\n",
    "    return pd.Series({'accuracy':accuracy_score(y_true, y_pred),\n",
    "                      'precision': precision_score(y_true, y_pred),\n",
    "                      'recall': recall_score(y_true, y_pred),\n",
    "                      'f1': f1_score(y_true, y_pred)},\n",
    "                      name=label)\n",
    "y_train_pred = dt.predict(X_train)\n",
    "y_test_pred = dt.predict(X_test)\n",
    "\n",
    "train_test_full_error = pd.concat([measure_error(y_train, y_train_pred, 'train'),\n",
    "                              measure_error(y_test, y_test_pred, 'test')],\n",
    "                              axis=1)\n",
    "\n",
    "\n",
    "By building a normal Decision Tree we receive a overfitting therefor I will use a Grid Search to find the best estimator\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'max_depth':range(1, dt.tree_.max_depth+1, 2),\n",
    "              'max_features': range(1, len(dt.feature_importances_)+1)}\n",
    "\n",
    "GR = GridSearchCV(DecisionTreeClassifier(random_state=42),\n",
    "                  param_grid=param_grid,\n",
    "                  scoring='accuracy',\n",
    "                  n_jobs=-1)\n",
    "\n",
    "GR = GR.fit(X_train, y_train)\n",
    "GR.best_estimator_.tree_.node_count, GR.best_estimator_.tree_.max_depth\n",
    "(15, 3)\n",
    "y_train_pred_gr = GR.predict(X_train)\n",
    "y_test_pred_gr = GR.predict(X_test)\n",
    "\n",
    "train_test_gr_error = pd.concat([measure_error(y_train, y_train_pred_gr, 'train'),\n",
    "                                 measure_error(y_test, y_test_pred_gr, 'test')],\n",
    "                                axis=1)\n",
    "\n",
    "the finall results show that Decision Tree can not be use on this data due to low precision and f1 scores.\n",
    "\n",
    "RandomForest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    " \n",
    "RF = RandomForestClassifier(oob_score=True, \n",
    "                            random_state=42, \n",
    "                            warm_start=True,\n",
    "                            n_jobs=-1)\n",
    "\n",
    "oob_list = list()\n",
    "\n",
    " \n",
    "for n_trees in [15, 20, 30, 40, 50, 100, 150, 200, 300, 400]:\n",
    "    \n",
    "    RF.set_params(n_estimators=n_trees)\n",
    "\n",
    "    RF.fit(X_train, y_train)\n",
    "\n",
    "    oob_error = 1 - RF.oob_score_\n",
    "    \n",
    "    oob_list.append(pd.Series({'n_trees': n_trees, 'oob': oob_error}))\n",
    "\n",
    "rf_oob_df = pd.concat(oob_list, axis=1).T.set_index('n_trees')\n",
    "\n",
    "\n",
    "sns.set_context('talk')\n",
    "sns.set_style('white')\n",
    "\n",
    "ax = rf_oob_df.plot(legend=False, marker='o', figsize=(14, 7), linewidth=5)\n",
    "ax.set(ylabel='out-of-bag error');\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    " \n",
    "EF = ExtraTreesClassifier(oob_score=True, \n",
    "                          random_state=42, \n",
    "                          warm_start=True,\n",
    "                          bootstrap=True,\n",
    "                          n_jobs=-1)\n",
    "\n",
    "oob_list = list()\n",
    "\n",
    " \n",
    "for n_trees in [15, 20, 30, 40, 50, 100, 150, 200, 300, 400]:\n",
    "    \n",
    "    EF.set_params(n_estimators=n_trees)\n",
    "    EF.fit(X_train, y_train)\n",
    "\n",
    "    oob_error = 1 - EF.oob_score_\n",
    "    oob_list.append(pd.Series({'n_trees': n_trees, 'oob': oob_error}))\n",
    "\n",
    "et_oob_df = pd.concat(oob_list, axis=1).T.set_index('n_trees')\n",
    "\n",
    "et_oob_df\n",
    "\n",
    "oob_df = pd.concat([rf_oob_df.rename(columns={'oob':'RandomForest'}),\n",
    "                    et_oob_df.rename(columns={'oob':'ExtraTrees'})], axis=1)\n",
    "\n",
    "\n",
    "sns.set_context('talk')\n",
    "sns.set_style('white')\n",
    "\n",
    "ax = oob_df.plot(marker='o', figsize=(14, 7), linewidth=5)\n",
    "ax.set(ylabel='out-of-bag error');\n",
    "\n",
    "model = RF.set_params(n_estimators=100)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "cr = classification_report(y_test, y_pred)\n",
    "print(cr)\n",
    "\n",
    "score_df = pd.DataFrame({'accuracy': accuracy_score(y_test, y_pred),\n",
    "                         'precision': precision_score(y_test, y_pred),\n",
    "                         'recall': recall_score(y_test, y_pred),\n",
    "                         'f1': f1_score(y_test, y_pred),\n",
    "                         'auc': roc_auc_score(y_test, y_pred)},\n",
    "                         index=pd.Index([0]))\n",
    "\n",
    "print(score_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
